{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "107731c6",
   "metadata": {},
   "source": [
    "This code is for preparing training dataset based on https://github.com/NVlabs/edm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eea636cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import gzip\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import sys\n",
    "import tarfile\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from typing import Callable, Optional, Tuple, Union\n",
    "import click\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b00945ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_bytes(fname: str, data: Union[bytes, str]):\n",
    "    os.makedirs(os.path.dirname(fname), exist_ok=True)\n",
    "    with open(fname, 'wb') as fout:\n",
    "        if isinstance(data, str):\n",
    "            data = data.encode('utf8')\n",
    "        fout.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e21955b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    \"./data\", download=True, train=True)\n",
    "target_cifar = torch.tensor(cifar10.targets)\n",
    "\n",
    "\n",
    "\n",
    "random_index = torch.randperm(len(target_cifar))\n",
    "random_target = target_cifar[random_index]\n",
    "\n",
    "\n",
    "sampled_index = torch.tensor([], dtype = int)\n",
    "sampled_target = torch.tensor([], dtype = int)\n",
    "\n",
    "for i in range(10):\n",
    "    sampled_index = torch.cat((sampled_index, random_index[torch.where(random_target==i)[0][:200]]))\n",
    "    sampled_target = torch.cat((sampled_target, target_cifar[random_index[torch.where(random_target==i)[0][:200]]]))\n",
    "    sampled_data = cifar10.data[sampled_index]\n",
    "\n",
    "torch.save(sampled_index, 'sampled_index.pt')\n",
    "samples = sampled_data\n",
    "label = sampled_target\n",
    "\n",
    "np.savez('sampled_data_with_label.npz', samples=samples, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c07d5e2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images = {'img': samples, \"label\" : label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "410cf58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_dest(dest: str):\n",
    "    dest_ext = file_ext(dest)\n",
    "    if dest_ext == 'zip':\n",
    "        if os.path.dirname(dest) != '':\n",
    "            os.makedirs(os.path.dirname(dest), exist_ok=True)\n",
    "        zf = zipfile.ZipFile(file=dest, mode='w', compression=zipfile.ZIP_STORED)\n",
    "        def zip_write_bytes(fname: str, data: Union[bytes, str]):\n",
    "            zf.writestr(fname, data)\n",
    "        return '', zip_write_bytes, zf.close\n",
    "    else:\n",
    "\n",
    "        if os.path.isdir(dest) and len(os.listdir(dest)) != 0:\n",
    "            raise click.ClickException('--dest folder must be empty')\n",
    "        os.makedirs(dest, exist_ok=True)\n",
    "\n",
    "        def folder_write_bytes(fname: str, data: Union[bytes, str]):\n",
    "            os.makedirs(os.path.dirname(fname), exist_ok=True)\n",
    "            with open(fname, 'wb') as fout:\n",
    "                if isinstance(data, str):\n",
    "                    data = data.encode('utf8')\n",
    "                fout.write(data)\n",
    "        return dest, folder_write_bytes, lambda: None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57a951f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_ext(name: Union[str, Path]):\n",
    "    return str(name).split('.')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3573cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_root_dir, save_bytes, close_dest = open_dest('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "429397d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "dataset_attrs = None\n",
    "channels = 3\n",
    "for idx, data in enumerate(zip(label, samples)):\n",
    "    image = {'img': data[1], \"label\" : int(data[0])}\n",
    "    idx_str = f'{idx:08d}'\n",
    "    archive_fname = f'{idx_str[:5]}/img{idx_str}.png'\n",
    "\n",
    "    # Apply crop and resize.\n",
    "    img = image['img']\n",
    "    if img is None:\n",
    "        continue\n",
    "\n",
    "    # Error check to require uniform image attributes across\n",
    "    # the whole dataset.\n",
    "#         channels = img.shape[2] if img.ndim == 3 else 1\n",
    "    cur_image_attrs = {'width': 32, 'height': 32, 'channels': 3}\n",
    "    if dataset_attrs is None:\n",
    "        dataset_attrs = cur_image_attrs\n",
    "        width = dataset_attrs['width']\n",
    "        height = dataset_attrs['height']\n",
    "        if width != height:\n",
    "            raise click.ClickException(f'Image dimensions after scale and crop are required to be square.  Got {width}x{height}')\n",
    "        if dataset_attrs['channels'] not in [1, 3]:\n",
    "            raise click.ClickException('Input images must be stored as RGB or grayscale')\n",
    "        if width != 2 ** int(np.floor(np.log2(width))):\n",
    "            raise click.ClickException('Image width/height after scale and crop are required to be power-of-two')\n",
    "    elif dataset_attrs != cur_image_attrs:\n",
    "        err = [f'  dataset {k}/cur image {k}: {dataset_attrs[k]}/{cur_image_attrs[k]}' for k in dataset_attrs.keys()]\n",
    "        raise click.ClickException(f'Image {archive_fname} attributes must be equal across all images of the dataset.  Got:\\n' + '\\n'.join(err))\n",
    "\n",
    "    # Save the image as an uncompressed PNG.\n",
    "    img = PIL.Image.fromarray(img, {1: 'L', 3: 'RGB'}[channels])\n",
    "    image_bits = io.BytesIO()\n",
    "    img.save(image_bits, format='png', compress_level=0, optimize=False)\n",
    "    save_bytes(os.path.join(archive_root_dir, archive_fname), image_bits.getbuffer())\n",
    "    labels.append([archive_fname, image['label']] if image['label'] is not None else None)\n",
    "\n",
    "metadata = {'labels': labels if all(x is not None for x in labels) else None}\n",
    "save_bytes(os.path.join(archive_root_dir, 'dataset.json'), json.dumps(metadata))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DPDM",
   "language": "python",
   "name": "dpdm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
